{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `kikuchipy` documentation https://kikuchipy.org.\n",
    "Links to the documentation won't work from the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern matching\n",
    "\n",
    "Crystal orientations can be determined from experimental EBSD patterns by\n",
    "matching them to simulated patterns of known phases and orientations, see\n",
    "e.g. <cite data-cite=\"chen2015dictionary\">Chen et al. (2015)</cite>,\n",
    "<cite data-cite=\"nolze2016pattern\">Nolze et al. (2016)</cite>, \n",
    "<cite data-cite=\"foden2019indexing\">Foden et al. (2019)</cite>.\n",
    "\n",
    "Here, we will demonstrate *dictionary indexing* (DI) using a small Ni EBSD data\n",
    "set and a dynamically simulated Ni master pattern from EMsoft, both of\n",
    "low resolution and found in the [kikuchipy.data](../reference.rst#data) module.\n",
    "The pattern dictionary is generated from a uniform grid of orientations with a\n",
    "fixed projection center (PC). The true orientation is likely to fall in between\n",
    "grid points, which means there is always a lower angular accuracy associated\n",
    "with DI. We can improve upon each solution by letting the orientation deviate\n",
    "from the grid points. We do this by maximizing the similarity between\n",
    "experimental and simulated patterns using numerical optimization algorithms from\n",
    "the [SciPy library](https://docs.scipy.org/doc/scipy/reference/optimize.html).\n",
    "This is here called *orientation refinement*. We could instead keep the\n",
    "orientations fixed and let the PC parameters deviate from their fixed values used\n",
    "in the dictionary, here called *projection center refinement*. Finally, we can\n",
    "also refine both at the same time, here called *orientation and projection center\n",
    "refinement*. The need for orientation or orientation and PC refinement is\n",
    "discussed by e.g.\n",
    "<cite data-cite=\"singh2017application\">Singh et al. (2017)</cite>,\n",
    "<cite data-cite=\"winkelmann2020refined\">Winkelmann et al. (2020)</cite>, and\n",
    "<cite data-cite=\"pang2020optimization\">Pang et al. (2020)</cite>.\n",
    "\n",
    "The term *pattern matching* is here used for the combined approach of DI\n",
    "followed by refinement.\n",
    "\n",
    "Before we can generate a dictionary of\n",
    "simulated patterns, we need a master pattern containing all possible scattering\n",
    "vectors for a candidate phase. This can be simulated using EMsoft\n",
    "(<cite data-cite=\"callahan2013dynamical\">Callahan and De Graef (2013)</cite> and\n",
    "<cite data-cite=\"jackson2014h5ebsd\">Jackson et al. (2014)</cite>) and then read\n",
    "into kikuchipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import libraries and load the small experimental Nickel test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange inline for notebook or qt5 (from pyqt) for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy.api as hs\n",
    "import numpy as np\n",
    "from orix import sampling, plot, io\n",
    "from orix.vector import Vector3d\n",
    "import kikuchipy as kp\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"figure.facecolor\": \"w\", \"font.size\": 15})\n",
    "\n",
    "# Use kp.load(\"data.h5\") to load your own data\n",
    "s = kp.data.nickel_ebsd_large(allow_download=True)  # External download\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain a good match, we must increase the signal-to-noise ratio. In this\n",
    "pattern matching analysis, the Kikuchi bands are considered the signal, and the\n",
    "angle-dependent backscatter intensity, along with unwanted detector effects,\n",
    "are considered to be noise. See the\n",
    "[pattern processing guide](pattern_processing.rst) for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.remove_static_background()\n",
    "s.remove_dynamic_background()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "DI is computationally intensive and takes in general a long time to run due to\n",
    "all the pattern comparisons being done. To maintain an acceptable memory usage\n",
    "and be done within reasonable time, it is recommended to write processed\n",
    "patterns to an HDF5 file for quick reading during DI.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.save(\"pattern_static_dynamic.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary indexing\n",
    "\n",
    "### Load a master pattern\n",
    "\n",
    "Next, we load a dynamically simulated Nickel master pattern generated with\n",
    "EMsoft, in the northern hemisphere projection of the square Lambert projection\n",
    "for an accelerating voltage of 20 keV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = 20\n",
    "mp = kp.data.nickel_ebsd_master_pattern_small(projection=\"lambert\", energy=energy)\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nickel phase information, specifically the crystal symmetry, asymmetric atom\n",
    "positions, and crystal lattice, is conveniently stored in an\n",
    "[orix.crystal_map.Phase](https://orix.readthedocs.io/en/stable/reference.html#orix.crystal_map.Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = mp.phase\n",
    "ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni.structure  # Element, x, y, z, site occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni.structure.lattice  # nm and degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample orientation space\n",
    "\n",
    "If we don't know anything about the possible crystal (unit cell) orientations in\n",
    "our sample, the safest thing to do is to generate a dictionary of orientations\n",
    "uniformly distributed in a candidate phase's orientation space. To achieve this,\n",
    "we sample the Rodrigues Fundamental Zone of the proper point group *432* using\n",
    "cubochoric sampling <cite data-cite=\"singh2016orientation\">Singh and De Graef\n",
    "(2016)</cite> available in\n",
    "[orix.sampling.get_sample_fundamental()](https://orix.readthedocs.io/en/stable/reference.html#orix.sampling.get_sample_fundamental). We can\n",
    "choose the average disorientation between orientations, the \"resolution\", of\n",
    "this sampling. Here, we will use a rather low resolution of 3$^{\\circ}$.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "Cubochoric sampling became available in orix v0.7.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotations = sampling.get_sample_fundamental(\n",
    "    method=\"cubochoric\", resolution=3, point_group=ni.point_group\n",
    ")\n",
    "rotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sampling resulted in 30 443 crystal orientations. See the [orix user guide\n",
    "on orientation sampling](https://orix.readthedocs.io/en/stable/uniform_sampling_of_orientation_space.html)\n",
    "for further details and options for orientation sampling.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "An average disorientation of 3$^{\\circ}$ results in a course sampling of\n",
    "orientation space; a lower average disorientation should be used for\n",
    "experimental work.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the detector-sample-geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our master pattern and crystal orientations, we need to\n",
    "describe the EBSD detector's position with respect to the sample (interaction\n",
    "volume). This ensures that projecting parts of the master pattern onto our\n",
    "detector yields dynamically simulated patterns resembling our experimental ones.\n",
    "See the [reference frames](reference_frames.rst) user guide and the\n",
    "[EBSDDetector](../reference.rst#kikuchipy.detectors.EBSDDetector)\n",
    "class for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_shape = s.axes_manager.signal_shape[::-1]\n",
    "detector = kp.detectors.EBSDDetector(\n",
    "    shape=signal_shape,\n",
    "    pc=[0.421, 0.7794, 0.5049],\n",
    "    sample_tilt=70,\n",
    "    convention=\"tsl\",\n",
    ")\n",
    "detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the projection/pattern center (PC) position on the detector\n",
    "using\n",
    "[plot()](../reference.rst#kikuchipy.detectors.EBSDDetector.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.plot(coordinates=\"gnomonic\", pattern=s.inav[0, 0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dictionary\n",
    "\n",
    "Now we're ready to generate our dictionary of simulated patterns by projecting\n",
    "parts of the master pattern onto our detector for all sampled orientations,\n",
    "using the\n",
    "[get_patterns()](../reference.rst#kikuchipy.signals.ebsdmasterpattern.get_patterns)\n",
    "method. The method assumes the crystal orientations are represented with respect\n",
    "to the EDAX TSL sample reference frame RD-TD-ND.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "It is in general adviced to not compute the dictionary immediately, but let the\n",
    "dictionary indexing method handle this, by passing `compute=False`. This will\n",
    "return a `LazyEBSD` signal, with the dictionary patterns as a\n",
    "[dask array](https://docs.dask.org/en/latest/array.html).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = mp.get_patterns(\n",
    "    rotations=rotations,\n",
    "    detector=detector,\n",
    "    energy=energy,\n",
    "    dtype_out=np.float32,\n",
    "    compute=True\n",
    ")\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the three first of the 30 443 simulated patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim.plot()  # Plot the patterns with a navigator for easy inspection\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(18, 6))\n",
    "for i in range(3):\n",
    "    ax[i].imshow(sim.inav[i].data, cmap=\"gray\")\n",
    "    euler = np.rad2deg(sim.xmap[i].rotations.to_euler())[0]\n",
    "    ax[i].set_title(\n",
    "        f\"($\\phi_1, \\Phi, \\phi_2)$ = {np.array_str(euler, precision=1)}\"\n",
    "    )\n",
    "    ax[i].axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform indexing\n",
    "\n",
    "*Signal masking was added in version: 0.5.*\n",
    "\n",
    "The Kikuchi pattern signal is usually weak towards the corners of the detector,\n",
    "so we can pass a signal mask to only match the pixels where the mask values are\n",
    "``False``, i.e. mask out the values that are ``True``. This convention is in\n",
    "line with how NumPy, Dask, scikit-image etc. defines a mask. We can pass\n",
    "whatever mask we want, as long as it is a boolean array of the detector shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_mask = ~kp.filters.Window(\"circular\", signal_shape).astype(bool)\n",
    "\n",
    "p = s.inav[0, 0].data\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax[0].imshow(p * signal_mask, cmap=\"gray\")\n",
    "ax[0].set_title(\"Not used in matching\")\n",
    "ax[1].imshow(p * ~signal_mask, cmap=\"gray\")\n",
    "ax[1].set_title(\"Used in matching\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use the\n",
    "[dictionary_indexing()](../reference.rst#kikuchipy.signals.EBSD.dictionary_indexing)\n",
    "method to match the simulated patterns to our experimental patterns, using\n",
    "the [zero-mean normalized cross correlation (NCC)](../reference.rst#kikuchipy.indexing.similarity_metrics.NormalizedCrossCorrelationMetric)\n",
    "coefficient $r$\n",
    "<cite data-cite=\"gonzalez2017digital\">Gonzalez & Woods (2017)</cite>, which is\n",
    "the default similarity metric. Let's keep the 20 best matching orientations. A\n",
    "number of 4125 * 30443 comparisons is quite small, which we can do in memory all\n",
    "at once. However, in cases where the number of comparisons are too big for our\n",
    "memory to handle, we should iterate over the dictionary of simulated patterns\n",
    "by passing the number of patterns per iteration. To demonstrate this, we do at\n",
    "least 10 iterations here. The results are returned as a\n",
    "[orix.crystal_map.CrystalMap](https://orix.readthedocs.io/en/stable/reference.html#crystalmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmap = s.dictionary_indexing(\n",
    "    sim,\n",
    "    metric=\"ncc\",\n",
    "    keep_n=20,\n",
    "    n_per_iteration=sim.axes_manager.navigation_size // 10,\n",
    "    signal_mask=signal_mask\n",
    ")\n",
    "xmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "*Added in version: 0.5.*\n",
    "    \n",
    "Dictionary indexing of real world data sets takes a long time because the\n",
    "matching is computationally intensive. The\n",
    "[dictionary_indexing()](../reference.rst#kikuchipy.signals.EBSD.dictionary_indexing)\n",
    "method accepts parameters *n_per_iteration*, *rechunk* and *dtype* that lets us\n",
    "control this behaviour to a certain extent, so be sure to take a look at the\n",
    "method's docstring.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [normalized dot product](../reference.rst#kikuchipy.indexing.similarity_metrics.NormalizedDotProductMetric)\n",
    "can be used instead of the NCC by passing `metric=\"ndp\"`. A custom metric can\n",
    "be used instead, by creating a class which inherits from the abstract class\n",
    "[SimilarityMetric](../reference.rst#kikuchipy.indexing.similarity_metrics.SimilarityMetric)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be exported to an HDF5 file re-readable by orix, or an\n",
    ".ang file readable by MTEX and some commercial packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = tempfile.mkdtemp() + \"/\"\n",
    "io.save(temp_dir + \"ni.h5\", xmap)\n",
    "io.save(temp_dir + \"ni.ang\", xmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze indexing results\n",
    "\n",
    "With the [orix library](https://orix.readthedocs.io) we can plot inverse pole\n",
    "figures (IPFs), color orientations to produce orientation maps (also called IPF\n",
    "maps), and more. If we want to inspect the results as grains, orientation\n",
    "density functions, or something else, we have to use other software, like MTEX.\n",
    "\n",
    "Let's generate an IPF color key and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckey = plot.IPFColorKeyTSL(ni.point_group)\n",
    "print(ckey)\n",
    "ckey.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this color key we can color orientations according to which\n",
    "crystal directions the sample direction $Z$ points in in every\n",
    "map pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx-thumbnail": {
     "tooltip": "Crystal orientation determination by comparing experimental EBSD patterns to a dictionary of simulated patterns obtained from a master pattern followed by orientation refinement"
    },
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "xmap.scan_unit = \"um\"\n",
    "xmap.plot(ckey.orientation2color(xmap.orientations), remove_padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a few more lines, we can plot maps for all three sample directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = xmap.orientations\n",
    "directions = Vector3d(((1, 0, 0), (0, 1, 0), (0, 0, 1)))\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 5), ncols=3)\n",
    "for ax, v, title in zip(axes, directions, (\"X\", \"Y\", \"Z\")):\n",
    "    ckey.direction = v\n",
    "    rgb = ckey.orientation2color(ori).reshape(xmap.shape + (3,))\n",
    "    ax.imshow(rgb)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"IPF {title}\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample is recrystallized Ni, so we expect a continuous color within\n",
    "grains, except for twinning grains. The orientation maps are mostly in\n",
    "line with our expectation. Some grains have a scatter of similar\n",
    "colors, which is most likely due to the discrete nature of our\n",
    "dictionary. To improve upon this result we can reduce the orientation\n",
    "sampling characteristic distance. This will increase our dictionary size\n",
    "and thus our indexing time. An alternative is to perform orientation\n",
    "refinement, which we will do below.\n",
    "\n",
    "We can get further confirmation of our initial analysis by inspecting\n",
    "some indexing quality maps, like the best matching scores and so-called\n",
    "orientation similarity (OS) map, which compares the best matching\n",
    "orientations for each pattern to it's nearest neighbours. Let's get the\n",
    "NCC map in the correct shape from the CrystalMapâ€™s scores property and\n",
    "the OS map with\n",
    "[orientation_similarity_map()](../reference.rst#kikuchipy.indexing.orientation_similarity_map)\n",
    "using the full list of best matches per point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_map = xmap.scores[:, 0].reshape(*xmap.shape)\n",
    "os_map = kp.indexing.orientation_similarity_map(xmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "im0 = ax[0].imshow(ncc_map)\n",
    "im1 = ax[1].imshow(os_map)\n",
    "fig.colorbar(im0, ax=ax[0], label=\"NCC\")\n",
    "fig.colorbar(im1, ax=ax[1], label=\"Orientation similarity\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the NCC map we see that some grains match better than others. Due to\n",
    "the discrete nature of our dictionary, it is safe to assume that the best\n",
    "matching grains have patterns more similar to those in the dictionary than\n",
    "the others, that is, the different coefficients does not reflect anything\n",
    "physical in the microstructure. The OS map doesn't tell us much more than\n",
    "the NCC map in this case.\n",
    "\n",
    "We can use the crystal map property `simulation_indices` to get the best\n",
    "matching simulated patterns from the dictionary of simulated patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_patterns = sim.data[xmap.simulation_indices[:, 0]].reshape(s.data.shape)\n",
    "s_best = kp.signals.EBSD(best_patterns)\n",
    "s_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to visually compare the experimental and best matching\n",
    "simulated patterns are to\n",
    "[plot them in the same navigator](visualizing_patterns.ipynb#plot-multiple-signals).\n",
    "Let's create an RGB navigator signal from the IPF $Z$ orientation map with the\n",
    "convenience function\n",
    "[get_rgb_navigator()](../reference.rst#kikuchipy.draw.get_rgb_navigator). When\n",
    "using an interactive backend like `Qt5Agg`, we can then move the red square\n",
    "around to look at the patterns in each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_navigator = kp.draw.get_rgb_navigator(rgb)\n",
    "hs.plot.plot_signals([s, s_best], navigator=rgb_navigator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the best matches for patterns from two grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grain1 = (0, 0)\n",
    "grain2 = (30, 10)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(10, 10))\n",
    "ax[0, 0].imshow(s.inav[grain1].data, cmap=\"gray\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "ax[0, 1].imshow(s_best.inav[grain1].data, cmap=\"gray\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "ax[1, 0].imshow(s.inav[grain2].data, cmap=\"gray\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "ax[1, 1].imshow(s_best.inav[grain2].data, cmap=\"gray\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "fig.tight_layout(h_pad=0.5, w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement\n",
    "\n",
    "Let's look at the effect of three refinement routes, all implemented as `EBSD`\n",
    "methods:\n",
    "\n",
    "1. Refine orientations while keeping the PCs fixed: [refine_orientation()](../reference.rst#kikuchipy.signals.EBSD.refine_orientation) \n",
    "2. Refine PCs while keeping the orientations fixed: [refine_projection_center()](../reference.rst#kikuchipy.signals.EBSD.refine_projection_center) \n",
    "3. Refine orientations and PCs at the same time: [refine_orientation_projection_center()](../reference.rst#kikuchipy.signals.EBSD.refine_orientation_projection_center) \n",
    "\n",
    "For each run we will compare the maps and histograms of NCC scores before and\n",
    "after refinement, and also the PC parameters if appropriate.\n",
    "\n",
    "As stated at the top, we use the numerical optimization routines from the\n",
    "[SciPy library](https://docs.scipy.org/doc/scipy/reference/optimize.html). For\n",
    "every orientation and/or PC, we want to iteratively increase the similarity (NCC\n",
    "score) between our experimental pattern and a new simulated pattern projected\n",
    "onto our EBSD detector for every iteration until the score increase from one\n",
    "iteration to the next is below a certain threshold, by default 0.0001 in most\n",
    "cases. The orientation and/or PC is updated slightly for every iteration. We\n",
    "have access to both local and global optimization algorithms. Consult the\n",
    "kikuchipy docstring methods linked below and the SciPy documentation for all\n",
    "available options.\n",
    "\n",
    "Note that while we here refine orientations obtained from DI, any orientation\n",
    "results, e.g. from Hough indexing, can be refined with this approach, as long as\n",
    "an appropriate master pattern and\n",
    "[EBSDDetector](../reference.rst#kikuchipy.detectors.EBSDDetector) is provided,\n",
    "and the orientation results are passed as a\n",
    "[CrystalMap](https://orix.readthedocs.io/en/stable/reference.html#orix.crystal_map.CrystalMap).\n",
    "\n",
    "### Refine orientations\n",
    "\n",
    "We use\n",
    "[refine_orientation()](../reference.rst#kikuchipy.signals.EBSD.refine_orientation)\n",
    "to refine orientations while keeping the PCs fixed, using the default local\n",
    "Nelder-Mead simplex method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmap_refined = s.refine_orientation(\n",
    "    xmap=xmap,\n",
    "    detector=detector,\n",
    "    master_pattern=mp,\n",
    "    energy=energy,\n",
    "    method=\"minimize\",  # Default\n",
    "    method_kwargs=dict(method=\"Nelder-Mead\", options=dict(fatol=1e-4)),  # Default\n",
    "    compute=True,  # Default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the NCC score maps. We use the same colorbar bounds for both maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_after_orientation_refinement = xmap_refined.get_map_data(\"scores\")\n",
    "\n",
    "ncc_di_min = np.min(ncc_map)\n",
    "ncc_di_max = np.max(ncc_map)\n",
    "ncc_ori_ref_min = np.min(ncc_after_orientation_refinement)\n",
    "ncc_ori_ref_max = np.max(ncc_after_orientation_refinement)\n",
    "\n",
    "vmin = min([ncc_di_min, ncc_ori_ref_min])\n",
    "vmax = max([ncc_di_max, ncc_ori_ref_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_after_label = \"NCC after ori. ref.\"\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "im0 = ax[0].imshow(ncc_map, vmin=vmin, vmax=vmax)\n",
    "im1 = ax[1].imshow(ncc_after_orientation_refinement, vmin=vmin, vmax=vmax)\n",
    "fig.colorbar(im0, ax=ax[0], label=\"NCC from DI\")\n",
    "fig.colorbar(im1, ax=ax[1], label=ncc_after_label)\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "fig.tight_layout(w_pad=-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(vmin, vmax, 100)\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "_ = ax.hist(ncc_map.ravel(), bins, alpha=0.5, label=\"NCC from DI\")\n",
    "_ = ax.hist(\n",
    "    ncc_after_orientation_refinement.ravel(),\n",
    "    bins,\n",
    "    alpha=0.5,\n",
    "    label=ncc_after_label,\n",
    ")\n",
    "ax.set_xlabel(\"Normalized cross correlation (NCC) scores\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.legend()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that DI found the best orientation (with a fixed PC) for most of the\n",
    "patterns, which the refinement was able to improve further. However, there\n",
    "are a few patterns with a very low NCC score (0.1-0.2) which refinement\n",
    "couldn't improve upon, which tells us that these were misindexed during DI.\n",
    "If there are Kikuchi bands in these patterns, a larger dictionary with a\n",
    "finer orientation sampling could improve indexing of them.\n",
    "\n",
    "Let's also plot the (IPF) $X$ orientation maps before and after refinement, and\n",
    "also the disorientation angle (smallest misorientation angle found after\n",
    "accounting for symmetry) difference between the two maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_ref = xmap_refined.orientations\n",
    "\n",
    "ckey.direction = Vector3d.xvector()\n",
    "rgb_z = ckey.orientation2color(ori)\n",
    "rgb_z_ref = ckey.orientation2color(ori_ref)\n",
    "\n",
    "mori_angle = np.rad2deg(ori.angle_with(ori_ref).data)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(14, 3))\n",
    "ax[0].imshow(rgb_z.reshape(xmap.shape + (3,)))\n",
    "ax[1].imshow(rgb_z_ref.reshape(xmap.shape + (3,)))\n",
    "im2 = ax[2].imshow(mori_angle.reshape(xmap.shape))\n",
    "fig.colorbar(im2, ax=ax[2], label=r\"Disorientation angle $\\omega$ [$^{\\circ}$]\")\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "fig.tight_layout(w_pad=-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that refinement was able to remove the scatter of similar colors\n",
    "in the grains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine projection centers\n",
    "\n",
    "We use\n",
    "[refine_projection_center()](../reference.rst#kikuchipy.signals.EBSD.refine_projection_center)\n",
    "to refine PCs while keeping the orientations fixed, using the local modified\n",
    "Powell method. This method is also known as Bound Optimization BY Quadratic\n",
    "Approximation (BOBYQA), and is used in EMsoft and discussed by\n",
    "<cite data-cite=\"singh2017application\">Singh et al. (2017)</cite>. We will pass\n",
    "a `trust_region` of +/- 5% for the PC parameters to use as upper and lower\n",
    "bounds during refinement.\n",
    "\n",
    "We can also pass `compute=False`, to do the\n",
    "refinement later. The results will then be a\n",
    "[dask.array.Array](https://docs.dask.org/en/latest/generated/dask.array.Array.html#dask.array.Array).\n",
    "We can pass this array to\n",
    "[kikuchipy.indexing.compute_refine_projection_center_results()](../reference.rst#kikuchipy.indexing.compute_refine_projection_center_results)\n",
    "and perform the refinement to retrieve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_array = s.refine_projection_center(\n",
    "    xmap=xmap,\n",
    "    detector=detector,\n",
    "    master_pattern=mp,\n",
    "    energy=energy,\n",
    "    method=\"minimize\",\n",
    "    method_kwargs=dict(method=\"Powell\", options=dict(ftol=1e-3)),\n",
    "    trust_region=[0.05, 0.05, 0.05],\n",
    "    compute=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_after_pc_refinement, detector_refined = kp.indexing.compute_refine_projection_center_results(\n",
    "    results=result_array, detector=detector, xmap=xmap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `refine_orientation()` and `refine_orientation_projection_center()`\n",
    "also takes the `compute` parameter, and there are similar functions to compute the\n",
    "refinement results:\n",
    "[kikuchipy.indexing.compute_refine_orientation_results()](../reference.rst#kikuchipy.indexing.compute_refine_orientation_results)\n",
    "and\n",
    "[kikuchipy.indexing.compute_refine_orientation_projection_center_results()](../reference.rst#kikuchipy.indexing.compute_refine_orientation_projection_center_results).\n",
    "\n",
    "Let's plot the refined scores and PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_pc_ref_min = np.min(ncc_after_pc_refinement)\n",
    "ncc_pc_ref_max = np.max(ncc_after_pc_refinement)\n",
    "\n",
    "vmin2 = min([ncc_di_min, ncc_pc_ref_min])\n",
    "vmax2 = max([ncc_di_max, ncc_pc_ref_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_after_pc_label = \"NCC after PC refinement\"\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "im0 = ax[0].imshow(ncc_map, vmin=vmin2, vmax=vmax2)\n",
    "im1 = ax[1].imshow(ncc_after_pc_refinement, vmin=vmin2, vmax=vmax2)\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "fig.colorbar(im0, ax=ax[0], label=\"NCC from DI\")\n",
    "fig.colorbar(im1, ax=ax[1], label=ncc_after_pc_label)\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(vmin2, vmax2, 100)\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "_ = ax.hist(ncc_map.ravel(), bins, alpha=0.5, label=\"NCC from DI\")\n",
    "_ = ax.hist(\n",
    "    ncc_after_pc_refinement.ravel(),\n",
    "    bins,\n",
    "    alpha=0.5,\n",
    "    label=ncc_after_pc_label,\n",
    ")\n",
    "ax.set_xlabel(\"Normalized cross correlation (NCC) scores\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.legend()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"PC used in DI:\\t\\t{detector.pc_average}\\n\"\n",
    "    f\"PC after PC refinement:\\t{detector_refined.pc_average}\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 3))\n",
    "im0 = ax[0].imshow(detector_refined.pcx)\n",
    "im1 = ax[1].imshow(detector_refined.pcy)\n",
    "im2 = ax[2].imshow(detector_refined.pcz)\n",
    "fig.colorbar(im1, ax=ax[1], label=\"Projection center y\")\n",
    "fig.colorbar(im0, ax=ax[0], label=\"Projection center x\")\n",
    "fig.colorbar(im2, ax=ax[2], label=\"Projection center z\")\n",
    "for a in ax:\n",
    "    a.axis(\"off\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine orientations and projection centers\n",
    "\n",
    "We use\n",
    "[refine_orientation_projection_center()](../reference.rst#kikuchipy.signals.EBSD.refine_orientation_projection_center)\n",
    "to refine orientations and PCs at the same time. For the purpose of saving time\n",
    "and computation resources in this demonstration, we'll do this for the upper left\n",
    "quarter of the data set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_shape = s.axes_manager.navigation_shape[::-1]\n",
    "y1, x1 = np.array(nav_shape) // 2\n",
    "slices2d = (slice(0, y1), slice(0, x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s.inav[slices2d[::-1]]  # HyperSpy flips the usual NumPy (row, column) to (column, row)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmap2 = xmap[slices2d]\n",
    "xmap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmap_refined2, detector_refined2 = s2.refine_orientation_projection_center(\n",
    "    xmap=xmap2,\n",
    "    detector=detector,\n",
    "    master_pattern=mp,\n",
    "    energy=energy,\n",
    "    method=\"minimize\",\n",
    "    method_kwargs=dict(options=dict(fatol=1e-3)),\n",
    "    compute=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmap_refined2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the NCC score maps. We use the same colorbar bounds for both maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_after_orientation_pc_refinement = xmap_refined2.get_map_data(\"scores\")\n",
    "ncc_map2 = ncc_map[slices2d]\n",
    "\n",
    "ncc2_di_min = np.min(ncc_map2)\n",
    "ncc2_di_max = np.max(ncc_map2)\n",
    "ncc_ori_pc_ref_min = np.min(ncc_after_orientation_pc_refinement)\n",
    "ncc_ori_pc_ref_max = np.max(ncc_after_orientation_pc_refinement)\n",
    "\n",
    "vmin3 = min([ncc2_di_min, ncc_ori_pc_ref_min])\n",
    "vmax3 = max([ncc2_di_max, ncc_ori_pc_ref_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc_after_ori_pc_label = \"NCC after ori./PC ref.\"\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(9, 3))\n",
    "im0 = ax[0].imshow(ncc_map2, vmin=vmin, vmax=vmax)\n",
    "im1 = ax[1].imshow(ncc_after_orientation_pc_refinement, vmin=vmin3, vmax=vmax3)\n",
    "fig.colorbar(im0, ax=ax[0], label=\"NCC from DI\")\n",
    "fig.colorbar(im1, ax=ax[1], label=ncc_after_ori_pc_label)\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(vmin3, vmax3, 100)\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "_ = ax.hist(ncc_map2.ravel(), bins, alpha=0.5, label=\"NCC from DI\")\n",
    "_ = ax.hist(\n",
    "    ncc_after_orientation_pc_refinement.ravel(),\n",
    "    bins,\n",
    "    alpha=0.5,\n",
    "    label=ncc_after_ori_pc_label,\n",
    ")\n",
    "ax.set_xlabel(\"Normalized cross correlation (NCC) scores\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.legend()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the refined PC parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"PC used in DI:\\t\\t{detector.pc_average}\\n\"\n",
    "    f\"PC after PC refinement:\\t{detector_refined2.pc_average}\"\n",
    ")\n",
    "\n",
    "pc_to_plot = (detector_refined2.pcx, detector_refined2.pcy, detector_refined2.pcz)\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 3))\n",
    "for a, to_plot, label in zip(ax, pc_to_plot, (\"x\", \"y\", \"z\")):\n",
    "    im = a.imshow(to_plot)\n",
    "    fig.colorbar(im, ax=a, label=f\"Projection center {label}\")\n",
    "    a.axis(\"off\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Remove files written to disk in this user guide\n",
    "import os\n",
    "os.remove(temp_dir + \"ni.h5\")\n",
    "os.remove(temp_dir + \"ni.ang\")\n",
    "os.rmdir(temp_dir)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
